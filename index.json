[{"uri":"https://thienluhoan.github.io/workshop-template/","title":"Information","tags":[],"description":"","content":"Information: Full Name: Nguy·ªÖn Th√†nh Nguy√™n\nPhone Number: 0935457152\nEmail: nguyen.fridayed@gmail.com\nUniversity: FPT University\nMajor: Information Assurance\nContent ECS-Fargate-Microservices "},{"uri":"https://thienluhoan.github.io/workshop-template/1-ecs-fargate-microservices/","title":"ECS Fargate Microservices","tags":[],"description":"","content":"This project implements a fully automated and secure microservices deployment platform on AWS, using ECS Fargate as the container orchestration engine and Terraform as the Infrastructure-as-Code (IaC) tool. The goal is to build a production-ready architecture that is scalable, cost-optimized, and security-hardened, while enabling rapid and reliable application delivery through a complete CI/CD pipeline.\nAt the core of the system is an ECS Fargate service that runs containerized microservices. All AWS infrastructure components‚Äîincluding networking, security, compute, storage, and monitoring‚Äîare provisioned through Terraform modules. The project integrates AWS CodeBuild and AWS CodePipeline, allowing application updates to be automatically built, containerized, pushed to Amazon ECR, and deployed to ECS whenever new code is pushed to GitHub.\nTo balance security and cost, the system operates within private subnets without a NAT Gateway. Instead, it uses a collection of VPC Interface Endpoints (ECR, S3, Secrets Manager, CloudWatch, etc.) to allow ECS tasks to securely pull images and access required AWS services without exposing resources to the public internet.\nSecurity is reinforced at multiple layers:\nAWS WAF protects the Application Load Balancer (ALB) from common web exploits.\nAmazon GuardDuty, VPC Flow Logs, and CloudWatch provide continuous threat detection and visibility.\nSecrets Manager is used to store sensitive credentials such as database passwords.\nRoute 53 provides custom domain management and DNS routing.\nThis project demonstrates a modern, cloud-native, and production-aligned approach to running microservices on AWS‚Äîcombining automation, observability, high availability, and strong security practices.\nThis this the architecture of the project:\n"},{"uri":"https://thienluhoan.github.io/workshop-template/1-ecs-fargate-microservices/1.1-introduction/","title":"Introduction","tags":[],"description":"","content":"This project implements a fully automated and secure microservices deployment platform on AWS, using ECS Fargate as the container orchestration engine and Terraform as the Infrastructure-as-Code (IaC) tool. The goal is to build a production-ready architecture that is scalable, cost-optimized, and security-hardened, while enabling rapid and reliable application delivery through a complete CI/CD pipeline.\nAt the core of the system is an ECS Fargate service that runs containerized microservices. All AWS infrastructure components‚Äîincluding networking, security, compute, storage, and monitoring‚Äîare provisioned through Terraform modules. The project integrates AWS CodeBuild and AWS CodePipeline, allowing application updates to be automatically built, containerized, pushed to Amazon ECR, and deployed to ECS whenever new code is pushed to GitHub.\nTo balance security and cost, the system operates within private subnets without a NAT Gateway. Instead, it uses a collection of VPC Interface Endpoints (ECR, S3, Secrets Manager, CloudWatch, etc.) to allow ECS tasks to securely pull images and access required AWS services without exposing resources to the public internet.\nSecurity is reinforced at multiple layers:\nAWS WAF protects the Application Load Balancer (ALB) from common web exploits.\nAmazon GuardDuty, VPC Flow Logs, and CloudWatch provide continuous threat detection and visibility.\nSecrets Manager is used to store sensitive credentials such as database passwords.\nRoute 53 provides custom domain management and DNS routing.\nThis project demonstrates a modern, cloud-native, and production-aligned approach to running microservices on AWS‚Äîcombining automation, observability, high availability, and strong security practices.\nThis this the architecture of the project:\n"},{"uri":"https://thienluhoan.github.io/workshop-template/1-ecs-fargate-microservices/1.4-resources/1.4.1-vpc-subnets-and-security-groups/","title":"VPC, Subnets, Security Groups","tags":[],"description":"","content":"The architecture consists of one VPC named ecs-fargate-microservices-vpc. Inside this VPC, 6 subnets and 4 security groups are configured to ensure that the application is secure and follows best practices\nPublic Subnets (for the Application Load Balancer) There are two public subnets, and they are used to host the Application Load Balancer (ALB)\nSecurity Group for the ALB\nInbound rules:\nAllow HTTP (port 80)\nAllow HTTPS (port 443)\nThese ports allow users to access your website\nEgress rules:\nOnly the required ports are allowed (in this case, port 3000) based on the least privilege principle This helps minimize risks such as:\nData exfiltration ‚Äì containers sending data outside the network\nMalware communication ‚Äì connecting to malicious C2 servers\nLateral movement ‚Äì accessing internal services that should be restricted\nCompliance violations ‚Äì breaking security standards Private Subnets (for ECS Tasks) There are two private subnets where ECS Fargate tasks run\nSecurity Group for ECS Tasks\nInbound rules:\nOnly allow traffic from the public ALB security group on port 3000 (container\u0026rsquo;s application port) Egress rules:\nAllow port 53 (DNS)\nAllow port 443 (HTTPS)\nAllow port 3000 (App)\nAllow port 3306 (MySQl)\nThese are required for tasks to pull images, connect to AWS APIs, or resolve domain names\nPrivate Subnets (for RDS Database) There are two additional private subnets dedicated for the RDS instance\nSecurity Group for RDS\nInbound rules:\nOnly allow connections from the ECS task security group, using port 3306 (MySQL port) No outbound rules: the RDS database does not need internet access, so outbound traffic is blocked for security\nSecurity Group for the VPC Endpoint (ECR Endpoint) This security group is attached to the Interface VPC Endpoint used by ECS tasks to pull container images from ECR privately (without internet)\nInbound rules\nAllow HTTPS (443) from the ECS Task Security Group\nThis enables ECS tasks to access ECR through PrivateLink\nOutbound rules\nNo outbound (egress) rule is required\nLeaving egress empty is safe and follows strict least privilege best practice\n"},{"uri":"https://thienluhoan.github.io/workshop-template/1-ecs-fargate-microservices/1.4-resources/1.4.2-application-load-balancer/","title":"Application Load Balancer","tags":[],"description":"","content":"The architecture includes an Application Load Balancer (ALB) with a listener on port 80 and a target group with two IP-based targets\nListener (Port 80) Receives incoming HTTP requests from users\nForwards requests to the target group\nTarget Group (IP Targets) Contains two targets identified by IP addresses\nProvides flexibility to register any network-accessible endpoint\nTraffic flow: User ‚Üí ALB (port 80) ‚Üí Target Group ‚Üí Targets (IP)\n"},{"uri":"https://thienluhoan.github.io/workshop-template/1-ecs-fargate-microservices/1.2-prerequiste/","title":"Prerequiste","tags":[],"description":"","content":"Follow the steps below to prepare your environment before deploying the infrastructure\nClone the project from GitHub Open your terminal and clone the repository: git clone https://github.com/nguyennt-fpt/ecs-fargate-microserviecs\nInside the project folder, you will find two main components:\ngetting-started-app/ ‚Äì the source code used to build the Docker container ecs-project/ ‚Äì the Infrastructure as Code (IaC) built with Terraform Install required tools Make sure the following tools are installed on your machine: Terraform, Git, AWS CLI, Docker Configure AWS CLI with an Access Key Step 1 ‚Äî Create an Access Key\nLog in to the AWS Console, navigate to IAM, select Users, choose the user you want to use, go to the Security credentials tab, click Create access key Follow the instructions then copy the: Access Key ID, Secret Access Key Step 2 ‚Äî Configure a new AWS CLI profile\nOpen your terminal and run: aws configure \u0026ndash;profile terraform\nEnter the Access Key, Secret Access Key, region (e.g., ap-southeast-1), and output format\nStep 3 ‚Äî Set this profile as default\nOn Windows PowerShell or CMD: setx AWS_PROFILE \u0026ldquo;terraform\u0026rdquo;\nClose the terminal and open it again so the environment variable takes effect Create an ECR repository You need an Amazon ECR repository to store your Docker image\nIn the AWS Console, search for ECR, click Create repository\nEnter a repository name, click Create After creating it, open the repository and click View push commands.\nKeep this window open ‚Äî you will need those commands to push your image.\nBuild and push the Docker image Make sure Docker Desktop is installed and running\nOpen the folder: getting-started-app/\nOpen a terminal inside this folder\nPaste and execute the push commands copied from ECR (These commands will log in to ECR, build the image, tag it, and push it) After completing the commands, go back to the ECR console.\nYou should now see an image inside your repository. Update the Terraform configuration Copy the repository URI from your ECR repository (Example: 123456789012.dkr.ecr.ap-southeast-1.amazonaws.com/my-app)\nGo to the folder: ecs-project/ then rename the file: terraform.tfvars.example ‚Üí terraform.tfvars\nFind the variable container_image and paste the repository URI with the latest tag:\ncontainer_image = \u0026ldquo;123456789012.dkr.ecr.ap-southeast-1.amazonaws.com/my-app:latest\u0026rdquo;\n"},{"uri":"https://thienluhoan.github.io/workshop-template/1-ecs-fargate-microservices/1.4-resources/1.4.3-ecs-cluster/","title":"ECS Cluster","tags":[],"description":"","content":"On the AWS Console, when we view the ECS service, we can see a cluster The cluster has one service, which is currently running\nThis service is based on a task definition, which you can view in the Task Definition tab\nThe task definition specifies everything needed to run the containers, such as: ALB integration, desired number of tasks, auto scaling, rolling updates, etc In the Tasks section, you see the two running tasks. These are the two containers running the web app for this project\nHere, the desired task count is set to 2, so ECS ensures that two tasks are always running "},{"uri":"https://thienluhoan.github.io/workshop-template/1-ecs-fargate-microservices/1.3-provisioning-infrastructure/","title":"Provisioning Infrastructure","tags":[],"description":"","content":"Before you begin, make sure Terraform is installed on your machine\nYou can download and install it from the official website: https://developer.hashicorp.com/terraform\nAfter installing, verify it using: terraform -v You now have all the necessary tools to start provisioning the infrastructure\nStep 1: Open the project folder\nNavigate to the ecs-project folder and open a terminal inside this directory Step 2: Run Terraform commands\nYou will use three main Terraform commands. Here is what each one does:\nterraform init This command initializes the project It downloads the necessary providers (such as AWS) and prepares Terraform to run terraform plan This command shows you what Terraform will do before making any changes It generates a detailed execution plan so you can review all resources that will be created, modified, or removed terraform apply This command actually builds the infrastructure Terraform will ask you to confirm before proceeding. Once approved, it starts creating all the resources defined in your configuration files Step 3: Wait for deployment\nThe full provisioning process may take 15‚Äì20 minutes depending on the resources being created "},{"uri":"https://thienluhoan.github.io/workshop-template/1-ecs-fargate-microservices/1.4-resources/","title":"Resources","tags":[],"description":"","content":"Resources Created After Provisioning the Infrastructure with Terraform After running Terraform to set up the infrastructure, the following resources will be created:\nVPC, Subnets, and Security Groups The foundational networking components that provide isolated networks, routing, and traffic filtering rules\nApplication Load Balancer (ALB) Distributes incoming traffic across ECS services to ensure high availability and scalability\nECS Cluster A container orchestration environment where your services will run on AWS Fargate\nAWS WAF A web application firewall that helps protect applications from common web exploits\nVPC Flow Logs and Amazon GuardDuty Security and monitoring services that analyze network traffic and detect suspicious or malicious activity\nECR VPC Endpoints Private endpoints allowing ECS tasks to pull container images from Amazon ECR securely without using the public internet\nRDS and Secrets Manager A managed database instance and securely stored database credentials used by your application\n"},{"uri":"https://thienluhoan.github.io/workshop-template/1-ecs-fargate-microservices/1.4-resources/1.4.4-waf/","title":"Web Application Firewall","tags":[],"description":"","content":"The architecture includes an AWS Web Application Firewall (WAF) with several managed rules to protect the web application:\nAWSManagedRulesCommonRuleSet (700 WCU) ‚Äì protects against common web exploits such as XSS, path traversal, and other generic attacks\nAWSManagedRulesSQLiRuleSet (200 WCU) ‚Äì specifically protects against SQL Injection (SQLi) attacks that try to manipulate your database queries\nRateLimitRule ‚Äì limits the number of requests from a single client within a time period to prevent abuse, brute-force attacks, or DDoS attempts\nTogether, these rules help the application filter malicious traffic, prevent common web vulnerabilities, and improve security and compliance\nNote: Since the budget is limited, only basic managed rules are applied. If you want to enhance security, you can add additional WAF rules to cover more advanced threats\n"},{"uri":"https://thienluhoan.github.io/workshop-template/1-ecs-fargate-microservices/1.5-create-https-protocal/","title":"Create https Protocal","tags":[],"description":"","content":"Enabling HTTPS for the Web Application\nTo enable HTTPS, you first need a hosted zone in Route 53, which requires a registered domain name. You can purchase a domain from any domain provider and point its nameservers to Route 53\nStep 1: Create a Record in Route 53\nOpen Route 53 and go to your hosted zone\nClick Create record\nFor Record type, select A ‚Äì Routes traffic to an IPv4 address and some AWS resources\nUnder Route traffic to, select Alias to Application and Classic Load Balancer\nChoose your existing ALB and click Create record\nNow you can see a new record was created Step 2: Add an HTTPS Listener to the ALB\nGo to the EC2 console ‚Üí Load Balancing ‚Üí select your ALB Click Add listener and choose Protocol: HTTPS\nSelect the target group (ecs-fargate-microservices-tg)\nUnder Default SSL/TLS certificate, click Request a new ACM certificate Copy the domain name from the record you created in Route 53 into the ACM domain name field\nLeave other settings as default and click Create\nClick Create record in Route 53 to validate the certificate A new record was created in Route 53 Wait approximately 2 minutes for the certificate to be issued Return to the Add listener page, select the newly created certificate, and click Create Step 3: Redirect HTTP to HTTPS\nSelect the listener on port 80 ‚Üí Manage listener ‚Üí Edit listener Choose Redirect to URL and set Port: 443, then save the rule Step 4: Test the Configuration\nAccess your web application using HTTPS ‚Üí it should load successfully Access it using HTTP ‚Üí it should automatically redirect to HTTPS "},{"uri":"https://thienluhoan.github.io/workshop-template/1-ecs-fargate-microservices/1.4-resources/1.4.5-vpc-flow-log-and-guardduty/","title":"VPC Flow Log, GuardDuty","tags":[],"description":"","content":"The architecture also includes AWS GuardDuty and VPC Flow Logs to enhance security monitoring\nAWS GuardDuty is a threat detection service that continuously monitors your AWS accounts and workloads for malicious or unauthorized activity. It analyzes data from sources like VPC Flow Logs, CloudTrail events, and DNS logs to detect threats such as compromised instances, reconnaissance activities, or unusual API calls\nVPC Flow Logs capture information about the IP traffic going to and from network interfaces in your VPC. This allows you to monitor network activity, troubleshoot connectivity issues, and support security analysis by providing detailed traffic visibility\nTogether, GuardDuty and VPC Flow Logs help the project detect, investigate, and respond to potential security threats, improving overall cloud security\n"},{"uri":"https://thienluhoan.github.io/workshop-template/1-ecs-fargate-microservices/1.4-resources/1.4.6-ecr-endpoints/","title":"ECR Endpoint","tags":[],"description":"","content":"The project uses a VPC Endpoint for Amazon ECR instead of a NAT gateway to pull container images for ECS tasks\nA VPC Endpoint is a private connection between your VPC and AWS services, which allows resources in private subnets to access ECR without going through the public internet\nThis approach enhances security because the traffic remains within the AWS network, reducing exposure to potential external threats such as interception or attacks\nIt also simplifies network configuration since you don‚Äôt need to set up a NAT gateway or manage public IP addresses for your ECS tasks\nAdditionally, using a VPC Endpoint can help reduce data transfer costs, as traffic within the AWS network is often cheaper than sending it through a NAT gateway to the internet\nOverall, this setup ensures that your containers can securely and efficiently pull images from ECR while keeping them isolated in private subnets\n"},{"uri":"https://thienluhoan.github.io/workshop-template/1-ecs-fargate-microservices/1.6-test-auto-scaling/","title":"Testing auto scaling","tags":[],"description":"","content":"Testing ECS Service Auto Scaling\nNext, we will update the ECS service to verify that auto scaling is working correctly\nIn this architecture, the ECS Service is already configured with Auto Scaling using Terraform.\nHowever, to make testing more convenient, i will add an additional third policy This extra policy can be used to trigger scaling actions more aggressively or under different conditions, making it easier to observe and validate Auto Scaling behavior during load tests or demonstrations\nGo to ECS ‚Üí ecs-fargate-microservices-cluster ‚Üí select Update service\nIn the Service Auto Scaling section, click Add more scaling policy\nCreate a new scaling policy using the following settings:\nMetric: ALBRequestCountPerTarget\nTarget value: 50\nScale-out cooldown: 60 seconds\nScale-in cooldown: 300 seconds\nThese values make it easier to trigger scaling events for testing purposes\nTo generate traffic, use a load-testing tool such as Apache Bench (ab) Run the command: ab -n 10000 -c 20 your-domain-name\n-n 10000: total number of requests\n-c 20: number of concurrent requests\nAfter a short period, CloudWatch will detect increased load and trigger an alarm\nOnce the scaling policy activates, the number of running tasks will automatically increase\nIn this test, the service scaled from 2 tasks to 4 tasks\nThis confirms that the auto scaling configuration is working as expected\n"},{"uri":"https://thienluhoan.github.io/workshop-template/1-ecs-fargate-microservices/1.4-resources/1.4.7-rds-and-secret-manager/","title":"RDS, Secret Manager","tags":[],"description":"","content":"When you search for RDS in the AWS Management Console, you can see that an RDS instance has already been created\nTo enhance security, the project uses AWS Secrets Manager to store the RDS credentials\nBy using Terraform, the RDS instance and its credentials are defined as code, which means sensitive information like database passwords is not hardcoded anywhere in the application or task definitions\nTerraform provisions the RDS instance, the Secrets Manager secret, and links them automatically to ECS tasks or other applications\nSecrets Manager can automatically rotate credentials, reducing the risk of compromised passwords\nECS tasks can securely retrieve credentials at runtime without exposing them\nThis approach ensures that your database credentials are protected, managed, and securely accessed, while keeping the infrastructure fully automated and reproducible\n"},{"uri":"https://thienluhoan.github.io/workshop-template/1-ecs-fargate-microservices/1.7-test-waf-guardduty/","title":"Testing WAF and GuardDuty","tags":[],"description":"","content":"Testing AWS WAF Protection\nNext, I performed a few simple commands to verify whether AWS WAF is working correctly and blocking common attack patterns\nI sent several simulated malicious requests (such as SQL Injection and XSS payloads)\nThe response returned was 403 Forbidden, which confirms that WAF successfully blocked the requests\nI then checked the WAF dashboard in the AWS Management Console\nAfter a few test attempts, the number of blocked requests increased to 13, indicating that WAF is functioning properly and enforcing the configured rules as expected\nüîç Testing Amazon GuardDuty\nAfter verifying WAF, I proceeded to test Amazon GuardDuty\nBecause no real attack was occurring, I used the built-in AWS feature ‚ÄúGenerate Sample Findings‚Äù to simulate security findings\nRight after generating the sample findings, GuardDuty displayed:\nTotal findings: 374\nResources with findings: 16\nAccounts with findings: 1\nThese results confirm that GuardDuty is working correctly. It is able to detect threats, generate findings, and display detailed security insights in real time.\n"},{"uri":"https://thienluhoan.github.io/workshop-template/1-ecs-fargate-microservices/1.8-cicd/","title":"CICD","tags":[],"description":"","content":"Implementing CI/CD for Automated Build, Deployment, and Rolling Update\nNow I will implement a CI/CD workflow so that whenever a developer pushes a new version of the application to GitHub, the code will be automatically built, the Docker image will be pushed to ECR, and the ECS service will perform a rolling update with zero downtime\nCreating the CodeBuild Project Go to AWS CodeBuild and create a new project\nSource provider: Select GitHub\nIf this is the first time connecting to GitHub, authorize the connection\nChoose the repository that contains the application source code(In this case is getting-started-app)\nFor the webhook option, select: \u0026ldquo;Manually create a webhook for this repository in the GitHub console\u0026rdquo;\nIn the Buildspec section, select \u0026ldquo;Use a buildspec file\u0026rdquo;\nLeave the filename empty because in the getting-started-app folder, there is already a file named buildspec.yml CodeBuild will automatically detect this file (If you use a different filename, enter the name here)\nCopy the webhook URL provided by CodeBuild\nAdd webhook in GitHub, go to your GitHub repository ‚Üí Settings ‚Üí Webhooks, click Add webhook\nPaste the webhook URL copied from CodeBuild, save the webhook\nEnsuring IAM Permissions for CodeBuild Make sure that the CodeBuild service role contains the necessary permissions so it can:\nPull dependencies\nBuild Docker images\nPush images to Amazon ECR\nInteract with CloudWatch Logs\nInteract with S3 (if artifacts are stored there)\nWithout these permissions, the build process will fail\nCreating the CodePipeline Go to AWS CodePipeline and create a new pipeline\nChoose \u0026ldquo;Build a custom pipeline\u0026rdquo;\nFor the Source stage:\nSelect GitHub\nChoose the repository\nSet Webhook event type = Push\nFor the Build stage:\nSelect AWS CodeBuild\nChoose the CodeBuild project created earlier\nFor the Deploy stage:\nInput artifact: choose the BuildArtifact\nDeploy provider: Amazon ECS\nChoose the ECS cluster and service that were created previously\nClick Create to initialize the pipeline\nMake sure the role of CodePipeline has permission to do the job\nTesting the CI/CD Pipeline Now make a small change in the source code and push it to GitHub\nOnce the push is completed:\nCodePipeline will automatically start running\nThe build stage will build the Docker image and push it to ECR\nThe deploy stage will update the ECS service\nObserving the Rolling Update\nAfter a short time, in the ECS service:\nThe number of running tasks increases to 4 (2 old tasks + 2 new tasks created for the rolling update)\nAfter the new tasks pass health checks, ECS will terminate the 2 old tasks\nThis confirms that the rolling update worked correctly\nFinally, visit the website again\nThe application now shows the updated version, meaning the CI/CD pipeline is functioning as expected\nNavigate to ECR, there are a new image was push on the repository\n"},{"uri":"https://thienluhoan.github.io/workshop-template/categories/","title":"Categories","tags":[],"description":"","content":""},{"uri":"https://thienluhoan.github.io/workshop-template/tags/","title":"Tags","tags":[],"description":"","content":""}]